[net]

M=1600
height=1
filters=1600

# Transformer Block 1

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600

# Transformer Block 2

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 3

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 4

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 5

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600

# Transformer Block 6

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600

# Transformer Block 7

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 8

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 9

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 10

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600

# Transformer Block 11

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600

# Transformer Block 12

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 13

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 14

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 15

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600

# Transformer Block 16

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600

# Transformer Block 17

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 18

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 19

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 20

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600

# Transformer Block 21

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600

# Transformer Block 22

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 23

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 24

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 25

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600

# Transformer Block 26

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600

# Transformer Block 27

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 28

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 29

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 30

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600

# Transformer Block 31

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600

# Transformer Block 32

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 33

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 34

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 35

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600

# Transformer Block 36

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600

# Transformer Block 37

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 38

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 39

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 40

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600

# Transformer Block 41

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600

# Transformer Block 42

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 43

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 44

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 45

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600

# Transformer Block 46

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600

# Transformer Block 47

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600


# Transformer Block 48

[layernorm]
M=1600

# Key
[matmul]
M=1600
n_head=25
n_embd=1600

# Query
[matmul]
parent=-2
M=1600
n_head=25
n_embd=1600

# Value
[matmul]
parent=-3
M=1600
n_head=25
n_embd=1600

[attention_k]
parent=-2
from=-3
M=1
K=64
n_head=25
n_embd=1600
masked=1

[attention_v]
from=-2
M=1600
n_head=25
n_embd=1600

[matmul]
M=1600

[shortcut]
from=-8
M=1600

[layernorm]
M=1600

[matmul]
M=6400
activation=gelu_acc

[matmul]
M=1600

[shortcut]
from=-4
M=1600
